# -*- coding: utf-8 -*-
"""Almanac-creation-from-scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7xw-uyAg0Ls6SodgGGi_FaX5kvykFnN?resourcekey=0-ggYKMsVlCx6Fuxs1XmCE4g
"""

pip install -qU langchain-openai langchain langchain_community openai

import getpass
import os

os.environ["OPENAI_API_KEY"] = ""
os.environ['TAVILY_API_KEY'] = ''

from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo-0125")

from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate

tools = [TavilySearchResults(max_results=1)]

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Construct the Tools agent
agent = create_tool_calling_agent(llm, tools, prompt)

# Create an agent executor by passing in the agent and tools
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "what is LangChain?"})

import random
from collections import defaultdict

from openai import OpenAI
client = OpenAI()

def model_response(text):
    completion = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {
            "role": "user",
            "content": f"{text}"
        }
    ]
)

    return completion.choices[0].message.content

# Hypothetical function to get model responses


def agent_response(text_input):
   output = agent_executor.invoke({"input": text_input})
   return output

class PlannerAgent:
    def __init__(self):
        self.sub_tasks = []

    def break_down_problem(self, problem):
        # Dynamically create sub-tasks (for simplicity, fixed 3 here)

        task_list = model_response(f'''Break down the problem:{problem} provided into 3 sub-tasks and return the sub tasks in the form of a list. Here are the rules:
        1.Each of the steps should be as specific and narrow to the problem at hand
        2.These three steps when executed step-by-step should lead to the final solution
        3.Make assumptions and put as much detail as possible in each of the sub-tasks
        Here is the format: [step 1; step 2; step 3]''')
        self.sub_tasks = task_list.split(';')

def choose_agent(task):
    # Logic for choosing the best agent based on the task
    # For now, just returning a random agent from a list of available agents
    agents = ['Researcher', 'Expert', 'Product Manager', 'Mathematician', 'Marketer', 'Teacher']
    return random.choice(agents)


class TaskAgent:
    def __init__(self, name):
        self.name = name

    def execute_task(self, task):
        # Simulate task execution and return model response
        return agent_response(f'Execute {task} as {self.name}')

class CritiqueAgent:
    def __init__(self):
        self.feedback = []

    def provide_feedback(self, outputs, problem, plan):
        # Provide feedback based on outputs (simulated)
        feedback = model_response(f'Analyze the {outputs} and check if they are in-line with the plan:{plan} and offer a solution to the problem {problem} ')
        self.feedback.append(f"{feedback}")  # Short feedback

class AgentSystem:
    def __init__(self):
        self.planner = PlannerAgent()
        self.critique = CritiqueAgent()
        self.memory = defaultdict(list)
        self.outputs = {}

    def run(self, problem):
        # Problem Breakdown
        self.planner.break_down_problem(problem)

        # Task Execution
        for sub_task in self.planner.sub_tasks:
            print ("Sub task", sub_task)
            agent_name = choose_agent(sub_task)
            agent = TaskAgent(agent_name)
            output = agent.execute_task(sub_task)
            self.memory[agent_name].append(output)
            self.outputs[agent_name] = output

        # Feedback Loop
        self.critique.provide_feedback(self.outputs,problem,self.planner.sub_tasks)

        # Improvement Loop (simulated by re-running the tasks)
        for agent_name, output in self.outputs.items():
            # Simulate rework based on feedback (for simplicity, just re-run the task)
            print(f"Reworking task for {agent_name}...")
            new_output = model_response(f"Reworked {output}")
            self.outputs[agent_name] = new_output

        # Final Compilation
        final_output = "\n".join([f"{agent_name}: {output}" for agent_name, output in self.outputs.items()])
        return final_output

# Example usage
if __name__ == "__main__":
    problem = "Analyze the impact of AI on education"
    system = AgentSystem()
    final_result = system.run(problem)
    print("Final Result:")
    print(final_result)

